{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrlVqe2d2tDPIXubm7poLP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhizpyH/Neural-Networks/blob/main/Assignment_2_Neural_Network_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "MSmKlDdYLesR"
      },
      "outputs": [],
      "source": [
        "#####################################################################################################################\n",
        "#   Assignment 2: Neural Network Analysis\n",
        "#   This is a starter code in Python 3.6 for a neural network.\n",
        "#   You need to have numpy and pandas installed before running this code.\n",
        "#   You need to complete all TODO marked sections\n",
        "#   You are free to modify this code in any way you want, but need to mention it\n",
        "#       in the README file.\n",
        "#\n",
        "#####################################################################################################################\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet:\n",
        "    def __init__(self, X, y):\n",
        "        self.raw_input = pd.concat([X, y], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Pre-processing the dataset, which would include\n",
        "    # standardization, normalization,\n",
        "    # categorical to numerical, etc\n",
        "    def preprocess(self):\n",
        "        self.processed_data = self.raw_input\n",
        "\n",
        "        # No null variables\n",
        "        self.processed_data = self.processed_data.dropna()\n",
        "\n",
        "        # Removing any redundant rows\n",
        "        self.processed_data = self.processed_data.drop_duplicates()\n",
        "\n",
        "        # Categorical to numerical\n",
        "        for column in self.processed_data.columns:\n",
        "            if self.processed_data[column].dtype == 'object':\n",
        "                if column == self.raw_input.columns[-1]: # This is the target column\n",
        "                    le = LabelEncoder()\n",
        "                    self.processed_data[column] = le.fit_transform(self.processed_data[column])\n",
        "                    self.processed_data[column] = to_categorical(self.processed_data[column])\n",
        "\n",
        "                else:\n",
        "                    self.processed_data[column] = pd.Categorical(self.processed_data[column]).codes\n",
        "\n",
        "\n",
        "        # Standardization\n",
        "        for column in self.processed_data.columns:\n",
        "            if self.processed_data[column].dtype in [np.float64, np.int64]:\n",
        "                mean = self.processed_data[column].mean()\n",
        "                std = self.processed_data[column].std()\n",
        "                if std != 0:\n",
        "                  self.processed_data[column] = (self.processed_data[column] - mean) / std\n",
        "\n",
        "        # Normalization\n",
        "        for column in self.processed_data.columns:\n",
        "            if self.processed_data[column].dtype in [np.float64, np.int64]:\n",
        "                min_val = self.processed_data[column].min()\n",
        "                max_val = self.processed_data[column].max()\n",
        "                if max_val - min_val != 0:\n",
        "                  self.processed_data[column] = (self.processed_data[column] - min_val) / (max_val - min_val)\n",
        "\n",
        "\n",
        "        return 0\n",
        "\n",
        "    # Train and evaluate models for all combinations of parameters\n",
        "    # specified in the init method. Obtain following outputs:\n",
        "    #   1. Training Accuracy and Error (Loss) for every model\n",
        "    #   2. Test Accuracy and Error (Loss) for every model\n",
        "    #   3. History Curve (Plot of Accuracy against training steps) for all\n",
        "    #       the models in a single plot. The plot should be color coded i.e.\n",
        "    #       different color for each model\n",
        "\n",
        "    def train_evaluate(self):\n",
        "        ncols = len(self.processed_data.columns)\n",
        "        nrows = len(self.processed_data.index)\n",
        "        X = self.processed_data.iloc[:, 0:(ncols - 3)] # Adjusting for one-hot encoded target\n",
        "        y = self.processed_data.iloc[:, (ncols-3):] # Adjusting for one-hot encoded target\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2)\n",
        "\n",
        "        # Below are the hyperparameters that you need to use for model evaluation\n",
        "        # You can assume any fixed number of neurons for each hidden layer.\n",
        "\n",
        "        activations = ['sigmoid', 'tanh', 'relu']\n",
        "        learning_rate = [0.01, 0.1]\n",
        "        max_iterations = [100, 200] # also known as epochs\n",
        "        num_hidden_layers = [2, 3]\n",
        "\n",
        "        # A loop to go through each activation\n",
        "        for h in num_hidden_layers:\n",
        "            for a in activations:\n",
        "                # 2 Hidden layers\n",
        "                if h == 2:\n",
        "                    model = tf.keras.Sequential([\n",
        "                        keras.Input(shape=(X_train.shape[1],)),\n",
        "                        tf.keras.layers.Dense(3000, activation=a),\n",
        "                        tf.keras.layers.Dense(1000, activation=a),\n",
        "                        tf.keras.layers.Dense(3, activation='softmax') # Changed to 3 units and softmax for multi-class\n",
        "                    ])\n",
        "                # 3 Hidden layers\n",
        "                else:\n",
        "                    model = tf.keras.Sequential([\n",
        "                        keras.Input(shape=(X_train.shape[1],)),\n",
        "                        tf.keras.layers.Dense(3000, activation=a),\n",
        "                        tf.keras.layers.Dense(1000, activation=a),\n",
        "                        tf.keras.layers.Dense(300, activation=a),\n",
        "                        tf.keras.layers.Dense(3, activation='softmax') # Changed to 3 units and softmax for multi-class\n",
        "                    ])\n",
        "                for lr in learning_rate:\n",
        "                    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                      loss='categorical_crossentropy', # Changed loss for multi-class\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "                    for i in max_iterations:\n",
        "                        history = model.fit(X_train, y_train, epochs=i)\n",
        "                        test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "                        # Plot the Training Accuracy and Error (Loss) for this model\n",
        "                        plt.plot(history.history['accuracy'])\n",
        "                        plt.title('Training Accuracy')\n",
        "                        plt.ylabel('Accuracy')\n",
        "                        plt.xlabel('Epoch')\n",
        "                        plt.show()\n",
        "\n",
        "                        # Test Accuracy and Error (Loss) for this model\n",
        "                        test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "                        print('Test accuracy:', test_acc)\n",
        "\n",
        "                        # Test Accuracy and Error (Loss) for this model in a plot\n",
        "                        plt.plot(history.history['loss'])\n",
        "                        plt.title('Training Error')\n",
        "                        plt.ylabel('Error')\n",
        "                        plt.xlabel('Epoch')\n",
        "                        plt.show()\n",
        "\n",
        "                        # History Curve (Plot of Accuracy against training steps) for the model in a single plot\n",
        "                        plt.plot(history.history['accuracy'])\n",
        "                        plt.title('History Curve')\n",
        "                        plt.ylabel('Accuracy')\n",
        "                        plt.xlabel('Epoch')\n",
        "                        plt.show()\n",
        "\n",
        "\n",
        "        # Table of model hyperparameters, training and test accuracies, and training and testing errors\n",
        "        table = pd.DataFrame(columns=['Activation', 'Learning Rate', 'Max Iterations', 'Num Hidden Layers', 'Training Accuracy', 'Training Error', 'Test Accuracy', 'Test Error'])\n",
        "        print(table)\n",
        "\n",
        "        return 0"
      ],
      "metadata": {
        "id": "1-P7T61QNys7"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9rZhYscqTLf",
        "outputId": "0979b9e9-d1ec-4f00-a82a-47883158df86"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "predict_students_dropout_and_academic_success = fetch_ucirepo(id=697)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = predict_students_dropout_and_academic_success.data.features\n",
        "y = predict_students_dropout_and_academic_success.data.targets\n",
        "\n",
        "# metadata\n",
        "print(predict_students_dropout_and_academic_success.metadata)\n",
        "\n",
        "# variable information\n",
        "print(predict_students_dropout_and_academic_success.variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfk2gg4YqUXo",
        "outputId": "db478004-b953-4463-e905-c8730e6373f5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 697, 'name': \"Predict Students' Dropout and Academic Success\", 'repository_url': 'https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success', 'data_url': 'https://archive.ics.uci.edu/static/public/697/data.csv', 'abstract': \"A dataset created from a higher education institution (acquired from several disjoint databases) related to students enrolled in different undergraduate degrees, such as agronomy, design, education, nursing, journalism, management, social service, and technologies.\\nThe dataset includes information known at the time of student enrollment (academic path, demographics, and social-economic factors) and the students' academic performance at the end of the first and second semesters. \\nThe data is used to build classification models to predict students' dropout and academic sucess. The problem is formulated as a three category classification task, in which there is a strong imbalance towards one of the classes.\", 'area': 'Social Science', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 4424, 'num_features': 36, 'feature_types': ['Real', 'Categorical', 'Integer'], 'demographics': ['Marital Status', 'Education Level', 'Nationality', 'Occupation', 'Gender', 'Age'], 'target_col': ['Target'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2021, 'last_updated': 'Mon Feb 26 2024', 'dataset_doi': '10.24432/C5MC89', 'creators': ['Valentim Realinho', 'Mónica Vieira Martins', 'Jorge Machado', 'Luís Baptista'], 'intro_paper': {'ID': 99, 'type': 'NATIVE', 'title': \"Early prediction of student's performance in higher education: a case study\", 'authors': 'Mónica V. Martins, Daniel Tolledo, Jorge Machado, Luís M. T. Baptista, and Valentim Realinho', 'venue': 'Trends and Applications in Information Systems and Technologies', 'year': 2021, 'journal': 'Advances in Intelligent Systems and Computing series', 'DOI': 'http://www.doi.org/10.1007/978-3-030-72657-7_16', 'URL': 'http://www.worldcist.org/2021/', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': None, 'purpose': 'The dataset was created in a project that aims to contribute to the reduction of academic dropout and failure in higher education, by using machine learning techniques to identify students at risk at an early stage of their academic path, so that strategies to support them can be put into place. \\n\\nThe dataset includes information known at the time of student enrollment – academic path, demographics, and social-economic factors. \\n\\nThe problem is formulated as a three category classification task (dropout, enrolled, and graduate) at the end of the normal duration of the course. \\n', 'funded_by': 'This dataset is supported by program SATDAP - Capacitação da Administração Pública under grant POCI-05-5762-FSE-000191, Portugal.', 'instances_represent': 'Each instance is a student', 'recommended_data_splits': 'The dataset was used, in our project, with a data split of 80% for training and 20% for test.', 'sensitive_data': None, 'preprocessing_description': 'We performed a rigorous data preprocessing to handle data from anomalies, unexplainable outliers, and missing values.', 'variable_info': None, 'citation': 'If you use this dataset in experiments for a scientific publication, please kindly cite our paper: \\nM.V.Martins, D. Tolledo, J. Machado, L. M.T. Baptista, V.Realinho. (2021) \"Early prediction of student’s performance in higher education: a case study\" Trends and Applications in Information Systems and Technologies, vol.1, in Advances in Intelligent Systems and Computing series. Springer. DOI: 10.1007/978-3-030-72657-7_16'}}\n",
            "                                              name     role         type  \\\n",
            "0                                   Marital Status  Feature      Integer   \n",
            "1                                 Application mode  Feature      Integer   \n",
            "2                                Application order  Feature      Integer   \n",
            "3                                           Course  Feature      Integer   \n",
            "4                       Daytime/evening attendance  Feature      Integer   \n",
            "5                           Previous qualification  Feature      Integer   \n",
            "6                   Previous qualification (grade)  Feature   Continuous   \n",
            "7                                      Nacionality  Feature      Integer   \n",
            "8                           Mother's qualification  Feature      Integer   \n",
            "9                           Father's qualification  Feature      Integer   \n",
            "10                             Mother's occupation  Feature      Integer   \n",
            "11                             Father's occupation  Feature      Integer   \n",
            "12                                 Admission grade  Feature   Continuous   \n",
            "13                                       Displaced  Feature      Integer   \n",
            "14                       Educational special needs  Feature      Integer   \n",
            "15                                          Debtor  Feature      Integer   \n",
            "16                         Tuition fees up to date  Feature      Integer   \n",
            "17                                          Gender  Feature      Integer   \n",
            "18                              Scholarship holder  Feature      Integer   \n",
            "19                               Age at enrollment  Feature      Integer   \n",
            "20                                   International  Feature      Integer   \n",
            "21             Curricular units 1st sem (credited)  Feature      Integer   \n",
            "22             Curricular units 1st sem (enrolled)  Feature      Integer   \n",
            "23          Curricular units 1st sem (evaluations)  Feature      Integer   \n",
            "24             Curricular units 1st sem (approved)  Feature      Integer   \n",
            "25                Curricular units 1st sem (grade)  Feature      Integer   \n",
            "26  Curricular units 1st sem (without evaluations)  Feature      Integer   \n",
            "27             Curricular units 2nd sem (credited)  Feature      Integer   \n",
            "28             Curricular units 2nd sem (enrolled)  Feature      Integer   \n",
            "29          Curricular units 2nd sem (evaluations)  Feature      Integer   \n",
            "30             Curricular units 2nd sem (approved)  Feature      Integer   \n",
            "31                Curricular units 2nd sem (grade)  Feature      Integer   \n",
            "32  Curricular units 2nd sem (without evaluations)  Feature      Integer   \n",
            "33                               Unemployment rate  Feature   Continuous   \n",
            "34                                  Inflation rate  Feature   Continuous   \n",
            "35                                             GDP  Feature   Continuous   \n",
            "36                                          Target   Target  Categorical   \n",
            "\n",
            "        demographic                                        description units  \\\n",
            "0    Marital Status  1 – single 2 – married 3 – widower 4 – divorce...  None   \n",
            "1              None  1 - 1st phase - general contingent 2 - Ordinan...  None   \n",
            "2              None  Application order (between 0 - first choice; a...  None   \n",
            "3              None  33 - Biofuel Production Technologies 171 - Ani...  None   \n",
            "4              None                            1 – daytime 0 - evening  None   \n",
            "5   Education Level  1 - Secondary education 2 - Higher education -...  None   \n",
            "6              None  Grade of previous qualification (between 0 and...  None   \n",
            "7       Nationality  1 - Portuguese; 2 - German; 6 - Spanish; 11 - ...  None   \n",
            "8   Education Level  1 - Secondary Education - 12th Year of Schooli...  None   \n",
            "9   Education Level  1 - Secondary Education - 12th Year of Schooli...  None   \n",
            "10       Occupation  0 - Student 1 - Representatives of the Legisla...  None   \n",
            "11       Occupation  0 - Student 1 - Representatives of the Legisla...  None   \n",
            "12             None                Admission grade (between 0 and 200)  None   \n",
            "13             None                                     1 – yes 0 – no  None   \n",
            "14             None                                     1 – yes 0 – no  None   \n",
            "15             None                                     1 – yes 0 – no  None   \n",
            "16             None                                     1 – yes 0 – no  None   \n",
            "17           Gender                                1 – male 0 – female  None   \n",
            "18             None                                     1 – yes 0 – no  None   \n",
            "19              Age                       Age of studend at enrollment  None   \n",
            "20             None                                     1 – yes 0 – no  None   \n",
            "21             None  Number of curricular units credited in the 1st...  None   \n",
            "22             None  Number of curricular units enrolled in the 1st...  None   \n",
            "23             None  Number of evaluations to curricular units in t...  None   \n",
            "24             None  Number of curricular units approved in the 1st...  None   \n",
            "25             None  Grade average in the 1st semester (between 0 a...  None   \n",
            "26             None  Number of curricular units without evalutions ...  None   \n",
            "27             None  Number of curricular units credited in the 2nd...  None   \n",
            "28             None  Number of curricular units enrolled in the 2nd...  None   \n",
            "29             None  Number of evaluations to curricular units in t...  None   \n",
            "30             None  Number of curricular units approved in the 2nd...  None   \n",
            "31             None  Grade average in the 2nd semester (between 0 a...  None   \n",
            "32             None  Number of curricular units without evalutions ...  None   \n",
            "33             None                              Unemployment rate (%)  None   \n",
            "34             None                                 Inflation rate (%)  None   \n",
            "35             None                                                GDP  None   \n",
            "36             None  Target. The problem is formulated as a three c...  None   \n",
            "\n",
            "   missing_values  \n",
            "0              no  \n",
            "1              no  \n",
            "2              no  \n",
            "3              no  \n",
            "4              no  \n",
            "5              no  \n",
            "6              no  \n",
            "7              no  \n",
            "8              no  \n",
            "9              no  \n",
            "10             no  \n",
            "11             no  \n",
            "12             no  \n",
            "13             no  \n",
            "14             no  \n",
            "15             no  \n",
            "16             no  \n",
            "17             no  \n",
            "18             no  \n",
            "19             no  \n",
            "20             no  \n",
            "21             no  \n",
            "22             no  \n",
            "23             no  \n",
            "24             no  \n",
            "25             no  \n",
            "26             no  \n",
            "27             no  \n",
            "28             no  \n",
            "29             no  \n",
            "30             no  \n",
            "31             no  \n",
            "32             no  \n",
            "33             no  \n",
            "34             no  \n",
            "35             no  \n",
            "36             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    neural_network = NeuralNet(X, y)\n",
        "    neural_network.preprocess()\n",
        "    neural_network.train_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvcIXCdp8e-4",
        "outputId": "120db73b-fecb-4c08-acef-0ff91e6eff61"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m 83/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.3284 - loss: 5.3382"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1603272201.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mneural_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2513552302.py\u001b[0m in \u001b[0;36mtrain_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}